# MLOps Loan Approval Prediction System

Manual loan approval processes in financial institutions are often slow and inconsistent, making automation both a technical and operational challenge. This project demonstrates how machine learning can automate and standardize such decisions, backed by an **end-to-end MLOps workflow**: data versioning, model training, experiment tracking, monitoring, CI/CD, and deployment on Google Cloud Run.

**Project Constraints:**

- Built as a portfolio project using a GCP free trial, so deployed services will be revoked after the trial period.
- No automated testing yet for model, data, or API components.
- Designed for cost efficiency rather than full-scale production scalability.

---

## üìä Dataset

The system is trained on the [Loan Approval Dataset](https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data/data).

Features include:

* Applicant age, income, credit score
* Loan amount, loan interest, loan percent income
* Previous loan default indicator

**Target variable:** loan approval (1 = approved, 0 = rejected)

---

## üõ†Ô∏è Technology Stack

* **ML / Training**: scikit-learn, XGBoost
* **Versioning**: DVC (data), MLflow (models) with DagsHub
* **Monitoring**: Evidently, Cloud Logging, Cloud Monitoring, Bigquery
* **Infrastructure**: Docker, Google Cloud Run, Artifact Registry
* **CI/CD**: GitHub Actions
* **Frontend**: HTML/CSS/JS

---

## üöÄ Key Features

* ‚úÖ Microservices architecture (Frontend, API, Model, Monitoring)
* ‚úÖ Data versioning with **DVC** + DagsHub remote storage
* ‚úÖ Model tracking with **MLflow** + DagsHub Registry
* ‚úÖ Drift detection using **Evidently**
* ‚úÖ Containerized services with **Docker & Docker Compose**
* ‚úÖ CI/CD with GitHub Actions ‚Üí **Cloud Run deployment**
* ‚úÖ Structured logs for prediction audit trail

---

## üìà Development Phases

1. **Phase 1** ‚Äì Modularization & Local Setup
   Split services, added Dockerfiles, and tested with Docker Compose.

2. **Phase 2** ‚Äì Versioning & Experiment Tracking
   Data with **DVC + DagsHub**, model runs with **MLflow**.

3. **Phase 3** ‚Äì Monitoring & Drift Detection
   Integrated Evidently reports, structured logging, Cloud Monitoring.

4. **Phase 4** ‚Äì CI/CD Automation
   GitHub Actions workflows to build ‚Üí push ‚Üí deploy services on Cloud Run.

5. **Phase 5** ‚Äì Continuous Retraining
   Automated retraining pipeline (scheduled monthly) ‚Üí pushes new models to MLflow ‚Üí triggers redeployment of model service.

   > Retraining was originally planned using model predictions stored in `data/simulation/current.jsonl` (for development), and model prediction logs stored in BigQuery (for production). However, this approach was cancelled because those predictions do not contain true ground-truth labels, which makes retraining unreliable and potentially misleading. The project now focuses on Phase 1-4 only.


---

## üèóÔ∏è Architecture Overview

<img width="726" height="636" alt="Image" src="https://github.com/user-attachments/assets/ef815cd6-08a6-4e1a-ab56-3e75bad1f22d" />

### Data Flow

* **Prediction**: User ‚Üí Frontend ‚Üí API ‚Üí Model
* **Logging**: API logs ‚Üí Cloud Logging ‚Üí BigQuery
* **Monitoring**: Cloud Monitoring for system metrics, Evidently for drift reports

### Automated Workflows

* **Deployment**: On push to main branch
* **Monitoring**: Manual review of Evidently reports with report periodically updated daily + Cloud Monitoring alerts (only for system metrics)

---

## üìÇ Project Structure

```
.
‚îú‚îÄ‚îÄ‚îÄ.github/workflows							
‚îÇ           api.yml							# API service CI/CD workflow
‚îÇ           dvc-push.yml					# DVC CI/CD workflow
‚îÇ           frontend.yml					# Frontend service CI/CD workflow
‚îÇ           model.yml						# Model service CI/CD workflow
‚îÇ           monitoring.yml					# Monitoring service CI/CD workflow
‚îÇ           orchestrate.yml					# CI/CD workflows orchestration
|           monitoring-periodic-update.yml   # Periodic update of Monitoring service CI/CD workflow
‚îÇ
‚îú‚îÄ‚îÄ‚îÄapi										
‚îÇ       app.py							# Production API service
‚îÇ       app_dev.py						# Local Development API service
‚îÇ       requirements.txt				# API service requirements
‚îÇ
‚îú‚îÄ‚îÄ‚îÄdata										
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄprocessed
‚îÇ   ‚îÇ       test_data.csv.dvc			# Test data tracked with DVC
‚îÇ   ‚îÇ       train_data.csv.dvc			# Train data tracked with DVC
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄraw
‚îÇ   ‚îÇ       loan_data.csv.dvc			# Raw data tracked with DVC
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄsimulation
‚îÇ           current.jsonl.dvc			# Local Development Prediction result JSONL tracked with DVC
|           prediction_dev_log.csv.dvc  # Local Development Evidently current data tracked with DVC
‚îÇ           reference_data.csv.dvc		# Evidently reference data tracked with DVC
‚îÇ
‚îú‚îÄ‚îÄ‚îÄdocker										
‚îÇ       Dockerfile.api					# Production Dockerfile API service 
‚îÇ       Dockerfile.frontend				# Production Dockerfile Frontend service
‚îÇ       Dockerfile.local.api			# Local Development Dockerfile API service 
‚îÇ       Dockerfile.local.frontend		# Local Development Dockerfile Frontend service
‚îÇ       Dockerfile.local.model			# Local Development Dockerfile Model service
‚îÇ       Dockerfile.local.monitoring		# Local Development Dockerfile Monitoring service
‚îÇ       Dockerfile.model				# Production Dockerfile Model service
‚îÇ       Dockerfile.monitoring			# Production Dockerfile Monitoring service
‚îÇ
‚îú‚îÄ‚îÄ‚îÄfrontend									
‚îÇ   ‚îÇ   app.py							# Production Frontend service
‚îÇ   ‚îÇ   app_dev.py						# Local Development Frontend service
‚îÇ   ‚îÇ   requirements.txt				# Frontend service requirements
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄstatic
‚îÇ   ‚îÇ       style.css					# Frontend styling
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄtemplates
‚îÇ           index.html					# Production Frontend service code
‚îÇ           index_dev.html				# Local Development Frontend service code
‚îÇ
‚îú‚îÄ‚îÄ‚îÄmodel										
‚îÇ   ‚îÇ   app.py							# Production Model service
‚îÇ   ‚îÇ   app_dev.py						# Local Development Model service
‚îÇ   ‚îÇ   inference.py					# Production inference script
‚îÇ   ‚îÇ   inference_dev.py				# Local Development inference script
‚îÇ   ‚îÇ   model.pkl.dvc					# Local Development model.pkl tracked with DVC
‚îÇ   ‚îÇ   modelling_refactor.py			# Local Development modelling script
‚îÇ   ‚îÇ   modelling_tuning.py				# Experiment model tuning script 
‚îÇ   ‚îÇ   preprocessing_refactor.py		# Experiment data raw preprocessing script
‚îÇ   ‚îÇ   requirements.txt				# Model service requirements
‚îÇ
‚îî‚îÄ‚îÄ‚îÄmonitoring									
‚îÇ   ‚îÇ   app.py							# Production Evidently Monitoring service							
‚îÇ   ‚îÇ   app_dev.py						# Local Development Evidently Monitoring service
‚îÇ   ‚îÇ   convert_dev_logs.py        		# Local Development converting current.jsonl logs
‚îÇ   ‚îÇ   evidently_profile.py			# Evidently Monitoring service profile
‚îÇ   ‚îÇ   requirements.txt				# Evidently Monitoring service requirements
‚îÇ
‚îú‚îÄ‚îÄ‚îÄdocker-compose.yml					# Local Development running services with docker compose
‚îú‚îÄ‚îÄ‚îÄrequirements.txt					# Requirements for cloning purpose
```

---

## ‚ö° Usage

> üëâ For full local development and production setup instructions, see [COMMAND.md](COMMAND.md).

---

## üîÅ Reproducibility

* **Data versioning**:

  * Training datasets tracked with **DVC**, stored remotely in DagsHub.
  * `.dvc` pointer files in Git ensure exact dataset versions can be restored with `dvc pull`.

* **Model versioning**:

  * Models logged and stored in **MLflow Registry** (DagsHub).
  * Each training run saves metrics, parameters, and artifacts for reproducibility.

* **Experiment tracking**:

  * MLflow logs allow to replay experiments and compare runs.
  * Training pipeline automatically logs new runs and saves the best model to MLflow.

* **Environment consistency**:

  * Dependencies pinned in `requirements.txt`.
  * Containerized with Docker for consistent runtime between local and production.

**To reproduce training:**

```bash
dvc pull data/processed/train_data.csv
python model/modelling_refactor.py
```

Take a look at below section in `model/modelling_refactor.py`

```bash
# Promote to Production stage
client = MlflowClient()
client.transition_model_version_stage(
    name="XGB-best-model-manual", # this is MLFLOW_MODEL_NAME
    version=model_info.registered_model_version,
    stage="Production" # this is MLFLOW_MODEL_STAGE
    )
```

Ensure the following variables are match for production, especially in: `model/inference.py`, `docker/Dockerfile.model`, and also in `.github/workflows/model.yml`
```bash
MLFLOW_MODEL_NAME # give the same value as name
MLFLOW_MODEL_STAGE # give the same value as stage
```

---

## üîÆ Future Work

* [ ] Data, ML Model, and Code Testing
* [ ] Add Evidently ‚Üí Cloud Monitoring alerts for drift
* [ ] Retraining configuration with ground-truth labels

---

## üìö References

* [DVC Docs](https://dvc.org/)
* [MLflow Docs](https://mlflow.org/)
* [Evidently Docs](https://evidentlyai.com/)
* [Drift Concept](https://learn.evidentlyai.com/ml-observability-course/module-2-ml-monitoring-metrics/data-prediction-drift)
* [Evidently Community Examples](https://github.com/evidentlyai/community-examples?tab=readme-ov-file)
* [Evidently Usage example](https://medium.com/@pranavk2208/detecting-data-drift-using-evidently-5c8643fd382d)

---

## üë©‚Äçüíª Author

This project was built by Roissyah Fernanda, as part of a personal initiative to explore end-to-end MLOps system design, from development to production deployment.

Some parts of the implementation and documentation were assisted by AI tools (e.g., for code refactoring, formatting, and technical writing support), while all system design, integration, and decision-making were independently developed by the author.

> Contributions, feedback, or collaboration requests are always welcome. Feel free to open an issue or submit a pull request!